{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.annotator import * \n",
    "from sparknlp.base import *\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from pyspark.ml import Pipeline\n",
    "import sparknlp  \n",
    "import nltk\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import spacy\n",
    "import dateparser.search\n",
    "\n",
    "# Start SparkNLP\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = spark.read.load(\"rel.tweets.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base_cased download started this may take some time.\n",
      "Approximate size to download 389.2 MB\n",
      "[OK!]\n",
      "pos_anc download started this may take some time.\n",
      "Approximate size to download 4.3 MB\n",
      "[OK!]\n",
      "ner_dl_bert download started this may take some time.\n",
      "Approximate size to download 15.5 MB\n",
      "[OK!]\n",
      "sentiment_vivekn download started this may take some time.\n",
      "Approximate size to download 873.6 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "#add Bert Embeddings required by the name entity reconizer\n",
    "bert_embed = BertEmbeddings()\\\n",
    "    .pretrained('bert_base_cased', 'en') \\\n",
    "    .setInputCols([\"sentences\",'tokens'])\\\n",
    "    .setOutputCol(\"embeddings\")\\\n",
    "    .setCaseSensitive(True)\\\n",
    "    .setPoolingLayer(0)\n",
    "    \n",
    "#pretrained pos tagger to identify part of speech\n",
    "pos_tagger = PerceptronModel()\\\n",
    "    .pretrained(\"pos_anc\")\\\n",
    "    .setInputCols([\"tokens\", \"sentences\"])\\\n",
    "    .setOutputCol(\"POS\")\n",
    "    \n",
    "#compute NER tags using pre-trained Bert model\n",
    "ner = NerDLModel()\\\n",
    "    .pretrained('ner_dl_bert')\\\n",
    "    .setInputCols([\"document\", \"tokens\", \"embeddings\"])\\\n",
    "    .setOutputCol(\"ner\")\n",
    "\n",
    "#sentiment detector\n",
    "sent_detector = ViveknSentimentModel()\\\n",
    "    .pretrained(\"sentiment_vivekn\")\\\n",
    "    .setInputCols([\"lemma\", \"document\"]) \\\n",
    "    .setOutputCol(\"sentiment\")\n",
    "    \n",
    "pipeline = Pipeline(stages=[bert_embed, pos_tagger, ner, sent_detector])\n",
    "m = pipeline.fit(tweets)\n",
    "tweets = m.transform(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.select(\"sentiment.result\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out location tokens that look like stopwords\n",
    "eng_stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#filter out location token wich are not tagged as nouns\n",
    "location_pos_tags = [\"NN\", \"NP\", \"NNP\", \"NNS\", \"NPS\", \"NNPS\"]\n",
    "\n",
    "@F.udf(ArrayType(StringType()))\n",
    "def get_locations(tokens, ner_tags, pos_tags, filter_pos = True):\n",
    "    \n",
    "    def check_token(token, pos_tag):\n",
    "        if token in eng_stopwords:\n",
    "            return False\n",
    "        if filter_pos and (pos_tag not in location_pos_tags):\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "    \n",
    "    locations = []\n",
    "    cur_loc = \"\"\n",
    "    i = 0\n",
    "    for ner_tag in ner_tags:\n",
    "        if ner_tag == \"B-LOC\":\n",
    "            if check_token(tokens[i], pos_tags[i]):\n",
    "                cur_loc = tokens[i]\n",
    "        elif ner_tag == \"I-LOC\":\n",
    "            if check_token(tokens[i], pos_tags[i]):\n",
    "                cur_loc += \" \" + tokens[i]\n",
    "        else:\n",
    "            if cur_loc != \"\":\n",
    "                locations.append(cur_loc)\n",
    "                cur_loc = \"\"\n",
    "        i += 1\n",
    "        \n",
    "    return locations if len(locations) else []\n",
    "\n",
    "tweets = tweets\\\n",
    "    .withColumn(\"Locations\", get_locations(tweets.tokens.result, tweets.ner.result, tweets.POS.result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look-up locations from a list of a predefined locations and values\n",
    "#https://github.com/napsternxg/TwitterNER/tree/master/data/cleaned/custom_lexicons\n",
    "\n",
    "locations = spark.read.option(\"header\", \"true\").option(\"sep\", \",\").csv(\"locations.txt\") \n",
    "venues = spark.read.option(\"header\", \"true\").option(\"sep\", \",\").csv(\"venues.txt\") \n",
    "\n",
    "locations = locations.select(locations.Location).distinct()\n",
    "venues = venues.select(venues.Venue).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recognize locations and tidy up results\n",
    "results = tweets\\\n",
    "    .join(venues, F.expr(\"array_contains(Locations, Venue)\"), \"left\")\\\n",
    "    .join(locations, F.expr(\"array_contains(Locations, Location)\"), \"left\")\\\n",
    "    .withColumn(\"RecognizedLocation\", F.expr(\"CASE WHEN Venue IS NOT NULL THEN Venue WHEN Location IS NOT NULL THEN Location ELSE NULL END\"))\\\n",
    "    .groupBy(\"tweet_id\", \"user_id\", \"dt\", \"tweet\", \"Locations\")\\\n",
    "    .agg(\n",
    "        F.collect_set(F.col(\"RecognizedLocation\")).alias(\"RecognizedLocations\"),        \n",
    "        F.collect_set(F.col(\"Artist\")).alias(\"Artists\"),\n",
    "        F.collect_set(F.col(\"sentiment.Result\")).alias(\"Sentiment\")\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use spacy library to recognize dates\n",
    "\n",
    "spacy_nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "@F.udf(ArrayType(StringType()))\n",
    "def get_dates(tweet):\n",
    "    dates = []\n",
    "    doc = spacy_nlp(tweet)\n",
    "    for entity in doc.ents:\n",
    "        if entity.label_ == \"DATE\":\n",
    "            dates.append(entity.text)\n",
    "            \n",
    "    return dates\n",
    "\n",
    "#use dateparser lib to process date strings and try to adjust them with respect to the twitter date\n",
    "@F.udf(ArrayType(StringType()))\n",
    "def process_dates(date_strings, tweet_dt):\n",
    "    dates = []\n",
    "\n",
    "    today = datetime.date.today()\n",
    "    tweet_dt = dateparser.parse(tweet_dt)\n",
    "    dt_diff = today - tweet_dt.date()\n",
    "    \n",
    "    for dt_str in date_strings:\n",
    "        parsed_dates = dateparser.search.search_dates(dt_str)\n",
    "        if parsed_dates:\n",
    "            for dt in parsed_dates:            \n",
    "                #parsed date\n",
    "                parsed_dt = dt[1]\n",
    "            \n",
    "                #check if parsed date is closer to today than to the twitter date\n",
    "                twitter_diff = parsed_dt.date() - tweet_dt.date()\n",
    "                today_diff = today - parsed_dt.date()\n",
    "            \n",
    "                if (abs(today_diff.days) < abs(twitter_diff.days)):\n",
    "                    #get the number of days between the current date and the twitter date\n",
    "                    #and adjust the parsed date\n",
    "                    parsed_dt = parsed_dt.date() - dt_diff\n",
    "\n",
    "                dates.append(str(parsed_dt))\n",
    "                \n",
    "    return dates\n",
    "\n",
    "results = results\\\n",
    "    .withColumn(\"Dates\", get_dates(results.tweet))\\\n",
    "    .withColumn(\"ProcessedDates\", process_dates(F.col(\"Dates\"), results.dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+-------------------+---------------+--------------------+------------+\n",
      "|  tweet_id|             Artists|           Locations|RecognizedLocations|          Dates|      ProcessedDates|   Sentiment|\n",
      "+----------+--------------------+--------------------+-------------------+---------------+--------------------+------------+\n",
      "|3986316035|         [Lady Gaga]|                  []|                 []|             []|                  []|[[positive]]|\n",
      "|4143687686|[Tommy Lee, Court...|             [Vegas]|            [Vegas]|             []|                  []|[[positive]]|\n",
      "|5627695652|         [Bob Dylan]|                  []|                 []|             []|                  []|[[negative]]|\n",
      "|5644862232|    [Britney Spears]|                  []|                 []|             []|                  []|[[positive]]|\n",
      "|5678086598|   [Michael Jackson]|                  []|                 []|             []|                  []|[[negative]]|\n",
      "|4098495551|         [Lady Gaga]|              [Raar]|                 []|             []|                  []|[[positive]]|\n",
      "|5091638472|        [Elton John]|[WATFORD, Sir, UK...|          [Sir, UK]|    [next year]|                  []|[[negative]]|\n",
      "|5979606016|      [Taylor Swift]|           [NJ, VIP]|               [NJ]|             []|                  []|[[positive]]|\n",
      "|5523340200|     [Justin Bieber]|                  []|                 []|             []|                  []|[[positive]]|\n",
      "|4388461986|      [Taylor Swift]|                  []|                 []|             []|                  []|[[positive]]|\n",
      "|5258765862|    [Kelly Clarkson]|                  []|                 []|             []|                  []|[[positive]]|\n",
      "|5743690327| [Bruce Springsteen]|    [Ohio, Michigan]|   [Michigan, Ohio]|             []|                  []|[[negative]]|\n",
      "|3701284318|    [Kaci Battaglia]|                  []|                 []|       [Monday]|        [2009-08-29]|[[positive]]|\n",
      "|5167400976|   [Ennio Morricone]|    [Hollywood Bowl]|                 []|             []|                  []|[[negative]]|\n",
      "|5814062810|     [Justin Bieber]|                  []|                 []|             []|                  []|[[positive]]|\n",
      "|6019033595| [Chrisette Michele]|  [Soultrain Awards]|                 []|[Sunday, 11/29]|[2009-11-20, 2010...|[[negative]]|\n",
      "|2096391756|      [Ani DiFranco]|                  []|                 []|      [October]|        [2009-11-09]|[[positive]]|\n",
      "|4019842286|         [Lady Gaga]|                  []|                 []|       [Sunday]|        [2009-09-11]|[[positive]]|\n",
      "|5335048477|  [Christina Milian]|                  []|                 []|             []|                  []|[[positive]]|\n",
      "|5571409057|    [Britney Spears]|         [Australia]|        [Australia]|             []|                  []|[[positive]]|\n",
      "+----------+--------------------+--------------------+-------------------+---------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Show results\n",
    "results\\\n",
    "    .select(\"tweet_id\", \"Artists\", \"Locations\", \"RecognizedLocations\", \"Dates\", \"ProcessedDates\", \"Sentiment\")\\\n",
    "    .show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('p3': venv)",
   "language": "python",
   "name": "python36864bitp3venv38f3a5947b564cb69cee0d670d158b95"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
